{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Data Engineer - LATAM\n",
    "\n",
    "Por: Camilo Gutierrez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el análisis de tweets en Python, se aborda la optimización tanto de la memoria como del tiempo de ejecución. Para la gestión eficiente de la memoria, se emplean estrategias que evitan cargar el archivo completo en la memoria, haciendo uso de librerías nativas de bajo nivel como json para la lectura línea por línea. Este enfoque minimiza el consumo de recursos. \n",
    "\n",
    "Por otro lado, para optimizar el tiempo de ejecución, se recurre a la librería Pandas. Esta herramienta ofrece un rendimiento superior en el procesamiento de grandes conjuntos de datos, permitiendo realizar operaciones de manera más rápida y eficiente. \n",
    "\n",
    "Al combinar estrategias específicas para cada objetivo, se logra un análisis integral que maximiza tanto la eficiencia en el manejo de la memoria como en el tiempo de ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el manejo de entorno virtuales y dependencias se usa Pipenv que es una herramienta útil para:\n",
    "\n",
    "* Aislar las dependencias de los proyectos\n",
    "* Registrar las versiones de las dependencias\n",
    "* Facilitar el mantenimiento de los proyectos\n",
    "* Facilitar la colaboración con otros desarrolladores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para optimizacion de tiempo y memoria\n",
    "from q1_memory import q1_memory\n",
    "from q1_time import q1_time\n",
    "from q2_memory import q2_memory\n",
    "from q2_time import q2_time\n",
    "from q3_memory import q3_memory\n",
    "from q3_time import q3_time\n",
    "import time\n",
    "\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Los repositorios de Git pueden volverse muy grandes si se suben archivos grandes, lo que puede hacer que sea más difícil trabajar con el repositorio. Por esta razón el archivo no se sube al repositorio (Se agregó al gitignore). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Las top 10 fechas donde hay más tweets. \n",
    "\n",
    "Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    \"\"\"\n",
    "    Obtiene las 10 fechas más activas y su usuario más activo correspondiente de un archivo JSON.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta al archivo JSON.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[datetime.date, str]]: lista de tuplas que contiene la fecha y el usuario más activo para cada fecha.\n",
    "    \"\"\"\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "    # Convertir 'date' a datetime y extraer la fecha\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "    # Extraer el nombre de usuario del diccionario anidado 'user'\n",
    "    df['username'] = df['user'].apply(lambda row: row['username'])\n",
    "\n",
    "    # Agrupar por 'date' y contar los tweets, obtener el usuario más activo por fecha\n",
    "    top_dates_df = df.groupby('date')['username'].agg(\n",
    "        total_tweets='size',\n",
    "        most_active_user=lambda x: x.value_counts().idxmax()\n",
    "    ).nlargest(10, columns='total_tweets')\n",
    "\n",
    "    # Convierte el resultado a una lista de tuplas\n",
    "    top_dates_list = top_dates_df[['most_active_user']].to_records().tolist()\n",
    "\n",
    "    return top_dates_list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2859.55 MiB, increment: 2739.30 MiB\n",
      "Execution time: 5.1993489265441895 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "%memit top_10 = q1_time(file_path)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    \"\"\"\n",
    "    Esta función lee un archivo JSON que contiene tweets y devuelve una lista de las 10 fechas con mayor cantidad de tweets,\n",
    "    junto con el usuario más activo para cada una de esas fechas.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta del archivo JSON que contiene los tweets.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[datetime.date, str]]: Una lista de tuplas que contiene la fecha y el usuario más activo para cada una de las 10 fechas con mayor cantidad de tweets.\n",
    "    \"\"\"\n",
    "    # Se inicializa los diccionarios para contabilizar la actividad de tweets\n",
    "    tweet_counts = defaultdict(int)  # Contador de tweets por fecha\n",
    "    tweets_activity = defaultdict(lambda: defaultdict(int))  # Contador de tweets por fecha y usuario\n",
    "\n",
    "    # Abrir el archivo JSON y procesar cada línea\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Leer los tweets desde la línea del archivo JSON\n",
    "            tweet = json.loads(line)\n",
    "            \n",
    "            # Extraer la fecha y el nombre de usuario del tweet\n",
    "            date = datetime.fromisoformat(tweet['date']).date()\n",
    "            username = tweet['user']['username']\n",
    "\n",
    "            # Contar la cantidad de tweets por fecha y usuario\n",
    "            tweet_counts[date] += 1\n",
    "            tweets_activity[date][username] += 1\n",
    "\n",
    "    # Obtener las 10 fechas con mayor cantidad de tweets\n",
    "    top_10_dates = Counter(tweet_counts).most_common(10)\n",
    "\n",
    "    # Encontrar el usuario más activo para cada una de las 10 fechas con mayor trafico\n",
    "    top_users = [(date, Counter(tweets_activity[date]).most_common(1)[0][0]) for date, _ in top_10_dates]\n",
    "\n",
    "    return top_users\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 305.50 MiB, increment: 0.23 MiB\n",
      "Execution time: 2.2031350135803223 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "%memit top_10 = q1_memory(file_path)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta aproximación al problema logra una reducción sustancial en el consumo máximo de memoria y también mejora significativamente la velocidad de ejecución. Esto se debe a que estamos manejando un conjunto de datos relativamente pequeño, haciendo que esta estrategia de optimización de memoria sea la solución más eficiente en términos de tiempo de ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los top 10 emojis más usados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para determinar si un texto contiene un emoji, se puede usar una expresión regular para buscar secuencias de caracteres Unicode que coincidan con el patrón de un emoji usando REGEX por ejemplo. Sin embargo, esto puede ser complejo y propenso a errores.\n",
    "\n",
    "Por eso se usa la libreria emoji que proporciona funciones integradas para extraer emojis de texto, lo que puede ser más eficiente que hacerlo manualmente. Ademas emoji admite una variedad de formatos de emojis, incluidos los emojis Unicode, los emojis HTML, entre otros.\n",
    "\n",
    "Nota: Si un tweet tiene un mismo emoji repetido, cada aparición se contará."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def count_emojis(text) -> Counter:\n",
    "    \"\"\"\n",
    "    Cuenta la cantidad de emojis en un texto.\n",
    "\n",
    "    Args:\n",
    "        text (str): El texto en el que se contarán los emojis.\n",
    "\n",
    "    Returns:\n",
    "        Counter: Un objeto Counter que contiene la cantidad de cada emoji encontrado en el texto.\n",
    "    \"\"\"\n",
    "    # Analiza el texto en busca de emojis y devuelve una lista de objetos EmojiData.\n",
    "    data = emoji.analyze(text)\n",
    "\n",
    "    # Extrae los caracteres de cada objeto EmojiMatch y los almacena en una lista.\n",
    "    emoji_list = [em.chars for em in data]\n",
    "\n",
    "    # Crea un objeto Counter a partir de la lista de emojis y devuelve el resultado.\n",
    "    return Counter(emoji_list) if emoji_list else None\n",
    "\n",
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Calcula los 10 emojis más comunes en un archivo JSON.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta al archivo JSON.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, int]]: Una lista de tuplas que contiene los emojis más comunes y su frecuencia.\n",
    "    \"\"\"\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    \n",
    "    # Se unen todo el contenido de los tweets en un solo string\n",
    "    conteo_de_emojis = count_emojis(\"\".join(df.content.values))\n",
    "    \n",
    "    return conteo_de_emojis.most_common(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2971.00 MiB, increment: 2665.50 MiB\n",
      "Execution time: 11.406476020812988 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('🙏', 5049),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2972),\n",
       " ('🌾', 2182),\n",
       " ('🇮🇳', 2086),\n",
       " ('🤣', 1668),\n",
       " ('✊', 1651),\n",
       " ('❤️', 1382),\n",
       " ('🙏🏻', 1317),\n",
       " ('💚', 1040)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "%memit top_10_emojis = q2_time(file_path)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "top_10_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Lee un archivo JSON y cuenta la frecuencia de los emojis en los tweets.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta del archivo JSON.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 emojis más comunes y su frecuencia.\n",
    "    \"\"\"\n",
    "    # Leer el archivo JSON\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        total_emoji_counter = Counter()\n",
    "        for line in file:\n",
    "            tweet = json.loads(line) \n",
    "            # Extraer los emojis de cada tweet\n",
    "            emoji_counter = count_emojis(tweet['content'])\n",
    "            if emoji_counter:\n",
    "                # Sumar los emojis de cada tweet al contador total \n",
    "                total_emoji_counter += emoji_counter\n",
    "\n",
    "    # Obtener los 10 emojis más comunes\n",
    "    top_emojis = total_emoji_counter.most_common(10)\n",
    "\n",
    "    return top_emojis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 493.14 MiB, increment: 0.05 MiB\n",
      "Execution time: 8.347600221633911 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('🙏', 5049),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2972),\n",
       " ('🌾', 2182),\n",
       " ('🇮🇳', 2086),\n",
       " ('🤣', 1668),\n",
       " ('✊', 1651),\n",
       " ('❤️', 1382),\n",
       " ('🙏🏻', 1317),\n",
       " ('💚', 1040)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "%memit top_10_emojis = q2_memory(file_path)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "top_10_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 histórico de usuarios más influyentes\n",
    "\n",
    "Al contar las menciones para determinar los usuarios más influyentes, se tuvo en cuenta que un solo tweet puede mencionar a uno o más usuarios. Cada mención se contó individualmente, independientemente de cuántas veces un usuario específico fue mencionado en un solo tweet. Se usa la columna **mentionedUsers**\n",
    "\n",
    "```python\n",
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Cuenta el número de veces que cada usuario mencionado aparece en un archivo que contiene tweets.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta al archivo que contiene los tweets.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, int]]: Una lista de tuplas, donde cada tupla contiene el nombre de usuario de un usuario mencionado\n",
    "        y el número de veces que fue mencionado, ordenado en orden descendente según el conteo de menciones.\n",
    "    \"\"\"\n",
    "   # Inicializar un contador para contar menciones de usuarios\n",
    "    mentioned_users_counter = Counter()\n",
    "\n",
    "    # Abrir el archivo JSON de tweets y procesar cada línea\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Iterar sobre cada línea del archivo\n",
    "        for line in file:\n",
    "            # Cargar el tweet desde la línea como un objeto JSON\n",
    "            tweet = json.loads(line)\n",
    "            \n",
    "            # Obtener la lista de usuarios mencionados en el tweet\n",
    "            mentioned_user = tweet['mentionedUsers']\n",
    "            \n",
    "            # Verificar si hay usuarios mencionados en el tweet\n",
    "            if not mentioned_user:\n",
    "                continue\n",
    "            \n",
    "            # Actualizar el contador para cada usuario mencionado en el tweet\n",
    "            for user in mentioned_user:\n",
    "                mentioned_users_counter[user['username']] += 1\n",
    "    \n",
    "    # Obtener las 10 menciones más comunes y convertirlas a una lista de tuplas\n",
    "    conteo_lista = mentioned_users_counter.most_common(10)\n",
    "    \n",
    "    # Devolver la lista de tuplas ordenada en orden descendente según el conteo de menciones\n",
    "    return conteo_lista\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 492.17 MiB, increment: 0.03 MiB\n",
      "Execution time: 2.184135913848877 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2265),\n",
       " ('Kisanektamorcha', 1840),\n",
       " ('RakeshTikaitBKU', 1644),\n",
       " ('PMOIndia', 1427),\n",
       " ('RahulGandhi', 1146),\n",
       " ('GretaThunberg', 1048),\n",
       " ('RaviSinghKA', 1019),\n",
       " ('rihanna', 986),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 926)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "%memit top_10_mentioned_users = q3_memory(file_path)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "top_10_mentioned_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Lee un archivo JSON desde la ruta especificada y cuenta cuántas veces se menciona cada usuario.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): La ruta al archivo JSON.\n",
    "        \n",
    "    Returns:\n",
    "        List[Tuple[str, int]]: Una lista de tuplas que contiene el nombre de usuario y la cantidad de menciones,\n",
    "                               ordenada en orden descendente según la cantidad.\n",
    "    \"\"\"\n",
    "     # Leer el archivo JSON en un DataFrame\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "     # Seleccionar la columna 'mentionedUsers' y eliminar filas con valores nulos\n",
    "    df_mentioned_users = df['mentionedUsers'].dropna()\n",
    "\n",
    "     # Aplicar una función para extraer los nombres de usuario y explotar las listas en filas separadas\n",
    "    df_mentioned_users = df_mentioned_users.apply(lambda x: [x['username'] for x in x]).explode()\n",
    "\n",
    "     # Contar la frecuencia de cada nombre de usuario\n",
    "    conteo = df_mentioned_users.value_counts()\n",
    "\n",
    "     # Convertir el resultado a un DataFrame, tomar las primeras 10 filas y convertir a lista de tuplas\n",
    "    conteo_list = conteo.to_frame().head(10).to_records().tolist()\n",
    "    \n",
    "     # Devolver la lista de tuplas ordenada en orden descendente según la cantidad de menciones\n",
    "    return conteo_list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2980.41 MiB, increment: 2488.23 MiB\n",
      "Execution time: 5.1369709968566895 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2265),\n",
       " ('Kisanektamorcha', 1840),\n",
       " ('RakeshTikaitBKU', 1644),\n",
       " ('PMOIndia', 1427),\n",
       " ('RahulGandhi', 1146),\n",
       " ('GretaThunberg', 1048),\n",
       " ('RaviSinghKA', 1019),\n",
       " ('rihanna', 986),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 926)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "%memit top_10_mentioned_users = q3_time(file_path)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "top_10_mentioned_users"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latam-L8orR2hh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
