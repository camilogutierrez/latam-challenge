{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Data Engineer - LATAM\n",
    "\n",
    "Por: Camilo Gutierrez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el an√°lisis de tweets en Python, se aborda la optimizaci√≥n tanto de la memoria como del tiempo de ejecuci√≥n. Para la gesti√≥n eficiente de la memoria, se emplean estrategias que evitan cargar el archivo completo en la memoria, haciendo uso de librer√≠as nativas de bajo nivel como json para la lectura l√≠nea por l√≠nea. Este enfoque minimiza el consumo de recursos. \n",
    "\n",
    "Por otro lado, para optimizar el tiempo de ejecuci√≥n, se recurre a la librer√≠a Pandas. Esta herramienta ofrece un rendimiento superior en el procesamiento de grandes conjuntos de datos, permitiendo realizar operaciones de manera m√°s r√°pida y eficiente. \n",
    "\n",
    "Al combinar estrategias espec√≠ficas para cada objetivo, se logra un an√°lisis integral que maximiza tanto la eficiencia en el manejo de la memoria como en el tiempo de ejecuci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el manejo de entorno virtuales y dependencias se usa Pipenv que es una herramienta √∫til para:\n",
    "\n",
    "* Aislar las dependencias de los proyectos\n",
    "* Registrar las versiones de las dependencias\n",
    "* Facilitar el mantenimiento de los proyectos\n",
    "* Facilitar la colaboraci√≥n con otros desarrolladores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para optimizacion de tiempo y memoria\n",
    "from q1_memory import q1_memory\n",
    "from q1_time import q1_time\n",
    "from q2_memory import q2_memory\n",
    "from q2_time import q2_time\n",
    "from q3_memory import q3_memory\n",
    "from q3_time import q3_time\n",
    "import time\n",
    "\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Los repositorios de Git pueden volverse muy grandes si se suben archivos grandes, lo que puede hacer que sea m√°s dif√≠cil trabajar con el repositorio. Por esta raz√≥n el archivo no se sube al repositorio (Se agreg√≥ al gitignore). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Las top 10 fechas donde hay m√°s tweets. \n",
    "\n",
    "Mencionar el usuario (username) que m√°s publicaciones tiene por cada uno de esos d√≠as."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    \"\"\"\n",
    "    Obtiene las 10 fechas m√°s activas y su usuario m√°s activo correspondiente de un archivo JSON.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta al archivo JSON.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[datetime.date, str]]: lista de tuplas que contiene la fecha y el usuario m√°s activo para cada fecha.\n",
    "    \"\"\"\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "    # Convertir 'date' a datetime y extraer la fecha\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "    # Extraer el nombre de usuario del diccionario anidado 'user'\n",
    "    df['username'] = df['user'].apply(lambda row: row['username'])\n",
    "\n",
    "    # Agrupar por 'date' y contar los tweets, obtener el usuario m√°s activo por fecha\n",
    "    top_dates_df = df.groupby('date')['username'].agg(\n",
    "        total_tweets='size',\n",
    "        most_active_user=lambda x: x.value_counts().idxmax()\n",
    "    ).nlargest(10, columns='total_tweets')\n",
    "\n",
    "    # Convierte el resultado a una lista de tuplas\n",
    "    top_dates_list = top_dates_df[['most_active_user']].to_records().tolist()\n",
    "\n",
    "    return top_dates_list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2859.55 MiB, increment: 2739.30 MiB\n",
      "Execution time: 5.1993489265441895 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "%memit top_10 = q1_time(file_path)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    \"\"\"\n",
    "    Esta funci√≥n lee un archivo JSON que contiene tweets y devuelve una lista de las 10 fechas con mayor cantidad de tweets,\n",
    "    junto con el usuario m√°s activo para cada una de esas fechas.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta del archivo JSON que contiene los tweets.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[datetime.date, str]]: Una lista de tuplas que contiene la fecha y el usuario m√°s activo para cada una de las 10 fechas con mayor cantidad de tweets.\n",
    "    \"\"\"\n",
    "    # Se inicializa los diccionarios para contabilizar la actividad de tweets\n",
    "    tweet_counts = defaultdict(int)  # Contador de tweets por fecha\n",
    "    tweets_activity = defaultdict(lambda: defaultdict(int))  # Contador de tweets por fecha y usuario\n",
    "\n",
    "    # Abrir el archivo JSON y procesar cada l√≠nea\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Leer los tweets desde la l√≠nea del archivo JSON\n",
    "            tweet = json.loads(line)\n",
    "            \n",
    "            # Extraer la fecha y el nombre de usuario del tweet\n",
    "            date = datetime.fromisoformat(tweet['date']).date()\n",
    "            username = tweet['user']['username']\n",
    "\n",
    "            # Contar la cantidad de tweets por fecha y usuario\n",
    "            tweet_counts[date] += 1\n",
    "            tweets_activity[date][username] += 1\n",
    "\n",
    "    # Obtener las 10 fechas con mayor cantidad de tweets\n",
    "    top_10_dates = Counter(tweet_counts).most_common(10)\n",
    "\n",
    "    # Encontrar el usuario m√°s activo para cada una de las 10 fechas con mayor trafico\n",
    "    top_users = [(date, Counter(tweets_activity[date]).most_common(1)[0][0]) for date, _ in top_10_dates]\n",
    "\n",
    "    return top_users\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 305.50 MiB, increment: 0.23 MiB\n",
      "Execution time: 2.2031350135803223 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "%memit top_10 = q1_memory(file_path)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta aproximaci√≥n al problema logra una reducci√≥n sustancial en el consumo m√°ximo de memoria y tambi√©n mejora significativamente la velocidad de ejecuci√≥n. Esto se debe a que estamos manejando un conjunto de datos relativamente peque√±o, haciendo que esta estrategia de optimizaci√≥n de memoria sea la soluci√≥n m√°s eficiente en t√©rminos de tiempo de ejecuci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los top 10 emojis m√°s usados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para determinar si un texto contiene un emoji, se puede usar una expresi√≥n regular para buscar secuencias de caracteres Unicode que coincidan con el patr√≥n de un emoji usando REGEX por ejemplo. Sin embargo, esto puede ser complejo y propenso a errores.\n",
    "\n",
    "Por eso se usa la libreria emoji que proporciona funciones integradas para extraer emojis de texto, lo que puede ser m√°s eficiente que hacerlo manualmente. Ademas emoji admite una variedad de formatos de emojis, incluidos los emojis Unicode, los emojis HTML, entre otros.\n",
    "\n",
    "Nota: Si un tweet tiene un mismo emoji repetido, cada aparici√≥n se contar√°."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def count_emojis(text) -> Counter:\n",
    "    \"\"\"\n",
    "    Cuenta la cantidad de emojis en un texto.\n",
    "\n",
    "    Args:\n",
    "        text (str): El texto en el que se contar√°n los emojis.\n",
    "\n",
    "    Returns:\n",
    "        Counter: Un objeto Counter que contiene la cantidad de cada emoji encontrado en el texto.\n",
    "    \"\"\"\n",
    "    # Analiza el texto en busca de emojis y devuelve una lista de objetos EmojiData.\n",
    "    data = emoji.analyze(text)\n",
    "\n",
    "    # Extrae los caracteres de cada objeto EmojiMatch y los almacena en una lista.\n",
    "    emoji_list = [em.chars for em in data]\n",
    "\n",
    "    # Crea un objeto Counter a partir de la lista de emojis y devuelve el resultado.\n",
    "    return Counter(emoji_list) if emoji_list else None\n",
    "\n",
    "def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Calcula los 10 emojis m√°s comunes en un archivo JSON.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta al archivo JSON.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, int]]: Una lista de tuplas que contiene los emojis m√°s comunes y su frecuencia.\n",
    "    \"\"\"\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    \n",
    "    # Se unen todo el contenido de los tweets en un solo string\n",
    "    conteo_de_emojis = count_emojis(\"\".join(df.content.values))\n",
    "    \n",
    "    return conteo_de_emojis.most_common(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2971.00 MiB, increment: 2665.50 MiB\n",
      "Execution time: 11.406476020812988 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('üôè', 5049),\n",
       " ('üòÇ', 3072),\n",
       " ('üöú', 2972),\n",
       " ('üåæ', 2182),\n",
       " ('üáÆüá≥', 2086),\n",
       " ('ü§£', 1668),\n",
       " ('‚úä', 1651),\n",
       " ('‚ù§Ô∏è', 1382),\n",
       " ('üôèüèª', 1317),\n",
       " ('üíö', 1040)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "%memit top_10_emojis = q2_time(file_path)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "top_10_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Lee un archivo JSON y cuenta la frecuencia de los emojis en los tweets.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta del archivo JSON.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, int]]: Una lista de tuplas que contiene los 10 emojis m√°s comunes y su frecuencia.\n",
    "    \"\"\"\n",
    "    # Leer el archivo JSON\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        total_emoji_counter = Counter()\n",
    "        for line in file:\n",
    "            tweet = json.loads(line) \n",
    "            # Extraer los emojis de cada tweet\n",
    "            emoji_counter = count_emojis(tweet['content'])\n",
    "            if emoji_counter:\n",
    "                # Sumar los emojis de cada tweet al contador total \n",
    "                total_emoji_counter += emoji_counter\n",
    "\n",
    "    # Obtener los 10 emojis m√°s comunes\n",
    "    top_emojis = total_emoji_counter.most_common(10)\n",
    "\n",
    "    return top_emojis\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 493.14 MiB, increment: 0.05 MiB\n",
      "Execution time: 8.347600221633911 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('üôè', 5049),\n",
       " ('üòÇ', 3072),\n",
       " ('üöú', 2972),\n",
       " ('üåæ', 2182),\n",
       " ('üáÆüá≥', 2086),\n",
       " ('ü§£', 1668),\n",
       " ('‚úä', 1651),\n",
       " ('‚ù§Ô∏è', 1382),\n",
       " ('üôèüèª', 1317),\n",
       " ('üíö', 1040)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "%memit top_10_emojis = q2_memory(file_path)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "top_10_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 hist√≥rico de usuarios m√°s influyentes\n",
    "\n",
    "Al contar las menciones para determinar los usuarios m√°s influyentes, se tuvo en cuenta que un solo tweet puede mencionar a uno o m√°s usuarios. Cada menci√≥n se cont√≥ individualmente, independientemente de cu√°ntas veces un usuario espec√≠fico fue mencionado en un solo tweet. Se usa la columna **mentionedUsers**\n",
    "\n",
    "```python\n",
    "def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Cuenta el n√∫mero de veces que cada usuario mencionado aparece en un archivo que contiene tweets.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): La ruta al archivo que contiene los tweets.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, int]]: Una lista de tuplas, donde cada tupla contiene el nombre de usuario de un usuario mencionado\n",
    "        y el n√∫mero de veces que fue mencionado, ordenado en orden descendente seg√∫n el conteo de menciones.\n",
    "    \"\"\"\n",
    "   # Inicializar un contador para contar menciones de usuarios\n",
    "    mentioned_users_counter = Counter()\n",
    "\n",
    "    # Abrir el archivo JSON de tweets y procesar cada l√≠nea\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        # Iterar sobre cada l√≠nea del archivo\n",
    "        for line in file:\n",
    "            # Cargar el tweet desde la l√≠nea como un objeto JSON\n",
    "            tweet = json.loads(line)\n",
    "            \n",
    "            # Obtener la lista de usuarios mencionados en el tweet\n",
    "            mentioned_user = tweet['mentionedUsers']\n",
    "            \n",
    "            # Verificar si hay usuarios mencionados en el tweet\n",
    "            if not mentioned_user:\n",
    "                continue\n",
    "            \n",
    "            # Actualizar el contador para cada usuario mencionado en el tweet\n",
    "            for user in mentioned_user:\n",
    "                mentioned_users_counter[user['username']] += 1\n",
    "    \n",
    "    # Obtener las 10 menciones m√°s comunes y convertirlas a una lista de tuplas\n",
    "    conteo_lista = mentioned_users_counter.most_common(10)\n",
    "    \n",
    "    # Devolver la lista de tuplas ordenada en orden descendente seg√∫n el conteo de menciones\n",
    "    return conteo_lista\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 492.17 MiB, increment: 0.03 MiB\n",
      "Execution time: 2.184135913848877 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2265),\n",
       " ('Kisanektamorcha', 1840),\n",
       " ('RakeshTikaitBKU', 1644),\n",
       " ('PMOIndia', 1427),\n",
       " ('RahulGandhi', 1146),\n",
       " ('GretaThunberg', 1048),\n",
       " ('RaviSinghKA', 1019),\n",
       " ('rihanna', 986),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 926)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "%memit top_10_mentioned_users = q3_memory(file_path)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "top_10_mentioned_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Lee un archivo JSON desde la ruta especificada y cuenta cu√°ntas veces se menciona cada usuario.\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): La ruta al archivo JSON.\n",
    "        \n",
    "    Returns:\n",
    "        List[Tuple[str, int]]: Una lista de tuplas que contiene el nombre de usuario y la cantidad de menciones,\n",
    "                               ordenada en orden descendente seg√∫n la cantidad.\n",
    "    \"\"\"\n",
    "     # Leer el archivo JSON en un DataFrame\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "     # Seleccionar la columna 'mentionedUsers' y eliminar filas con valores nulos\n",
    "    df_mentioned_users = df['mentionedUsers'].dropna()\n",
    "\n",
    "     # Aplicar una funci√≥n para extraer los nombres de usuario y explotar las listas en filas separadas\n",
    "    df_mentioned_users = df_mentioned_users.apply(lambda x: [x['username'] for x in x]).explode()\n",
    "\n",
    "     # Contar la frecuencia de cada nombre de usuario\n",
    "    conteo = df_mentioned_users.value_counts()\n",
    "\n",
    "     # Convertir el resultado a un DataFrame, tomar las primeras 10 filas y convertir a lista de tuplas\n",
    "    conteo_list = conteo.to_frame().head(10).to_records().tolist()\n",
    "    \n",
    "     # Devolver la lista de tuplas ordenada en orden descendente seg√∫n la cantidad de menciones\n",
    "    return conteo_list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2980.41 MiB, increment: 2488.23 MiB\n",
      "Execution time: 5.1369709968566895 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('narendramodi', 2265),\n",
       " ('Kisanektamorcha', 1840),\n",
       " ('RakeshTikaitBKU', 1644),\n",
       " ('PMOIndia', 1427),\n",
       " ('RahulGandhi', 1146),\n",
       " ('GretaThunberg', 1048),\n",
       " ('RaviSinghKA', 1019),\n",
       " ('rihanna', 986),\n",
       " ('UNHumanRights', 962),\n",
       " ('meenaharris', 926)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "%memit top_10_mentioned_users = q3_time(file_path)\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "top_10_mentioned_users"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latam-L8orR2hh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
